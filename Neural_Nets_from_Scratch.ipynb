{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjuZJzLIpi9huGVNcFWLcU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedembeddedx/ml-from-scratch/blob/main/Neural_Nets_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "5Zbm3vGtvdcw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import random\n",
        "from typing import List, Tuple, Dict, Union\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_breast_cancer()"
      ],
      "metadata": {
        "id": "m-I_a6Yavhyb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  a = 1/(1+np.exp(-x))\n",
        "  return a\n",
        "\n",
        "def cost(y, y_pred):\n",
        "  return (-y * np.log(y_pred)) + ((1 - y) * np.log(1 - y_pred))\n",
        "\n",
        "def loss_function(y, y_pred):\n",
        "\n",
        "  tc = 0\n",
        "  for i in range(len(y_pred)-1):\n",
        "    tc +=  cost(y[i], y_pred[i])\n",
        "\n",
        "  return tc/len(y_pred)\n",
        "\n",
        "def predict_y(weights, bias, x_params):\n",
        "  y = bias\n",
        "  for i in range(len(weights)-1):\n",
        "    y += (weights[i] * x_params[i])\n",
        "  return sigmoid(y)"
      ],
      "metadata": {
        "id": "kzLmoI6NvjK7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['data']\n",
        "X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "Y = data['target'].reshape(data['target'].shape[0],1)"
      ],
      "metadata": {
        "id": "kt9nCKrIvm7y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X Shape: {X.shape}\")\n",
        "print(f\"Y Shape: {Y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_jrLjCfvsUc",
        "outputId": "286b43d6-0e8c-4132-bed3-ff1a59f6f29a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Shape: (569, 31)\n",
            "Y Shape: (569, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def neuron(m: int):\n",
        "  if(m < 0):\n",
        "    print('Unable to compute this layer')\n",
        "  weights = np.random.rand(m)\n",
        "  bias = np.random.rand(1)\n",
        "  a = 0.05\n",
        "  return {'weights':weights, 'bias':bias}\n",
        "\n",
        "def layer(n: int, m: int):\n",
        "  if(m < 0):\n",
        "    print('Unable to compute this layer')\n",
        "  li = []\n",
        "\n",
        "  for i in range(0, n):\n",
        "    li.append(neuron(m))\n",
        "  return li"
      ],
      "metadata": {
        "id": "PG3nCvScvtX5"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1 = layer(5, 3)\n",
        "\n",
        "for i in l1:\n",
        "  print(predict_y(i['weights'], i['bias'], X[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGhKWJIzv7Eh",
        "outputId": "ac720167-f574-4e68-e12f-f38ae05b3d3f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.98489862]\n",
            "[0.99893661]\n",
            "[0.99999998]\n",
            "[0.99996165]\n",
            "[0.99274829]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def network(inputs: int, layers: int, neurons: List[int]):\n",
        "  ntw = []\n",
        "  if(layers != len(neurons)):\n",
        "    print('Unable to compute this network')\n",
        "    return ntw\n",
        "  else:\n",
        "    for i in range(0, layers):\n",
        "      l = layer(neurons[i], inputs)\n",
        "      ntw.append(l)\n",
        "\n",
        "    return ntw"
      ],
      "metadata": {
        "id": "Q6NSGbipyUeE"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ntw = network(X.shape[1], 5, [30, 40, 15, 8, 1])\n",
        "\n",
        "for i, j in zip(ntw, range(len(ntw))):\n",
        "  print(f'Layer {j+1}')\n",
        "  print(pd.DataFrame(i))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZhd2KgC0XtX",
        "outputId": "70dfb094-992a-473c-eb27-7a16822932fe"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1\n",
            "                                              weights                   bias\n",
            "0   [0.27193312276558634, 0.19083446604492182, 0.1...  [0.42725336490676713]\n",
            "1   [0.3463932555697926, 0.12964647554464048, 0.76...   [0.7911081921662964]\n",
            "2   [0.5293531643659808, 0.5146100390454046, 0.577...   [0.8983188656229727]\n",
            "3   [0.4290151432618091, 0.6869243178000163, 0.458...  [0.30366605204070185]\n",
            "4   [0.09535704067318163, 0.4570261739524738, 0.77...   [0.8962990971629805]\n",
            "5   [0.6995272163007585, 0.6522407733649164, 0.371...   [0.1433550882244763]\n",
            "6   [0.9536444966975249, 0.33989815055888817, 0.65...   [0.4568243871164177]\n",
            "7   [0.9574628451857609, 0.5267901932276664, 0.872...  [0.12166780200319427]\n",
            "8   [0.7337849185666343, 0.3688693258652359, 0.070...    [0.442947351463868]\n",
            "9   [0.165136210140727, 0.6563100176150432, 0.7767...   [0.7639999542562596]\n",
            "10  [0.035523829994546285, 0.1721186328817942, 0.1...   [0.8489149837453044]\n",
            "11  [0.23392348583249511, 0.8418497928928353, 0.55...   [0.9504864413238752]\n",
            "12  [0.9059211604301094, 0.3814021937553178, 0.955...  [0.38804043875559424]\n",
            "13  [0.2692120777022904, 0.309956002463474, 0.7165...  [0.20413903479123896]\n",
            "14  [0.6767212086243688, 0.8774961101621536, 0.322...   [0.8437356849780628]\n",
            "15  [0.4078594655449631, 0.8878168550583954, 0.645...  [0.39254202216145184]\n",
            "16  [0.0923072072483303, 0.4357954062266559, 0.003...  [0.48274877347670464]\n",
            "17  [0.8286611126583235, 0.24747184698998126, 0.22...   [0.7035363684845184]\n",
            "18  [0.1971651618538921, 0.6869196679776932, 0.809...  [0.25464426152715314]\n",
            "19  [0.9845092645047322, 0.9101405686243529, 0.602...    [0.833260027798068]\n",
            "20  [0.11180349049714122, 0.42935175656955427, 0.1...  [0.13495857555339863]\n",
            "21  [0.5941266876211638, 0.7670717562300136, 0.677...    [0.573243189169285]\n",
            "22  [0.6951514444248583, 0.8205950231257518, 0.281...   [0.5959766760889822]\n",
            "23  [0.9905027895497399, 0.5604793282344659, 0.692...  [0.22232543113683423]\n",
            "24  [0.018962261316032625, 0.20129681427686963, 0....   [0.2398039878142627]\n",
            "25  [0.8156986986843928, 0.5906864582614308, 0.720...   [0.3339238885382817]\n",
            "26  [0.6834970490667946, 0.1733960968811331, 0.198...   [0.1960365087119329]\n",
            "27  [0.44107402158260167, 0.45260125608000856, 0.5...  [0.44356337580278404]\n",
            "28  [0.6694562027728017, 0.4865032111956795, 0.166...   [0.0714412436394617]\n",
            "29  [0.3403439471742232, 0.2666530063465513, 0.986...   [0.3011841277418523]\n",
            "\n",
            "Layer 2\n",
            "                                              weights                    bias\n",
            "0   [0.26694607986977104, 0.7415495238345581, 0.08...    [0.9068093716870069]\n",
            "1   [0.24285690259277803, 0.18273489146375754, 0.3...  [0.026925286052309372]\n",
            "2   [0.5258758797626801, 0.7555460708906513, 0.679...    [0.4657676291854481]\n",
            "3   [0.9609796367547856, 0.6340591469784406, 0.146...    [0.9827742513499945]\n",
            "4   [0.6596689850340207, 0.8303774865250133, 0.333...    [0.7831752999846079]\n",
            "5   [0.017776593092542092, 0.37258399162768885, 0....    [0.2861203062461668]\n",
            "6   [0.03045733370153836, 0.09056598031638496, 0.0...    [0.8482563867469255]\n",
            "7   [0.9265443682596833, 0.240205816158499, 0.8636...    [0.2483229414391035]\n",
            "8   [0.8194871949244322, 0.7312141632390429, 0.854...     [0.676072056594296]\n",
            "9   [0.5405936224022743, 0.3835989975196997, 0.319...    [0.1960517419923149]\n",
            "10  [0.38378258053338166, 0.90519352768568, 0.3053...    [0.8335458588153201]\n",
            "11  [0.22463243357527662, 0.9223354379643326, 0.06...    [0.7531144708972988]\n",
            "12  [0.9409559552683352, 0.5489084154596127, 0.878...    [0.9507413367723667]\n",
            "13  [0.869765961730089, 0.145208014730703, 0.73137...   [0.34996023478959015]\n",
            "14  [0.7037775392385317, 0.46120092068028185, 0.46...     [0.949805743092614]\n",
            "15  [0.05438631021076468, 0.07124387177985281, 0.4...    [0.5534481516401046]\n",
            "16  [0.06949354524403772, 0.19779741279421492, 0.2...     [0.901593655303802]\n",
            "17  [0.8030770206192468, 0.06930753518692812, 0.86...   [0.16081120326812393]\n",
            "18  [0.550897467592683, 0.7300091821102396, 0.6298...     [0.972443846062369]\n",
            "19  [0.23739324589093846, 0.004459219461475539, 0....    [0.1731899991374013]\n",
            "20  [0.1917949950719523, 0.12439682298002974, 0.88...    [0.5872900924986619]\n",
            "21  [0.6655919010948257, 0.027050659947771005, 0.3...    [0.2891265598893743]\n",
            "22  [0.7310341116377252, 0.4829386770472587, 0.615...   [0.18928452634080906]\n",
            "23  [0.5932199321477091, 0.6801726524638035, 0.571...    [0.4433543387866963]\n",
            "24  [0.4226625732107041, 0.0014327213230789226, 0....   [0.06849604917583496]\n",
            "25  [0.19604404053700353, 0.23950529403373655, 0.6...   [0.08405031974906174]\n",
            "26  [0.36977996559869675, 0.13745453787694484, 0.5...    [0.8679961625061056]\n",
            "27  [0.38934733480542616, 0.7215902293472447, 0.67...    [0.3679439033107129]\n",
            "28  [0.6733727001646721, 0.94185044383725, 0.60249...     [0.673671728968635]\n",
            "29  [0.9185451292582424, 0.7618665930019063, 0.510...    [0.8829525973753759]\n",
            "30  [0.6392028941806082, 0.6593288248976377, 0.199...    [0.1093607264546348]\n",
            "31  [0.38125320415790287, 0.3480484308915812, 0.63...   [0.06489033383003595]\n",
            "32  [0.975839579090899, 0.6452367237838336, 0.3647...    [0.7210643919245171]\n",
            "33  [0.23269298143531247, 0.10173347010836131, 0.6...    [0.2513623543846133]\n",
            "34  [0.019497623629016525, 0.8029874808021382, 0.4...    [0.7827337492466041]\n",
            "35  [0.7403809427740573, 0.5324124569823591, 0.732...    [0.7563830767876965]\n",
            "36  [0.09769530989477315, 0.10545714583866239, 0.4...    [0.2717004192969201]\n",
            "37  [0.7236028591319988, 0.2982289444939684, 0.190...    [0.6925378007176528]\n",
            "38  [0.6094946614731329, 0.45985993336779574, 0.86...   [0.46053858299755646]\n",
            "39  [0.9506303941419654, 0.9422871849967638, 0.566...    [0.6119567654084506]\n",
            "\n",
            "Layer 3\n",
            "                                              weights                    bias\n",
            "0   [0.7489642425981238, 0.4225861257621504, 0.879...    [0.6437401619575815]\n",
            "1   [0.43266588168197495, 0.20039823187259198, 0.3...    [0.0981669299544059]\n",
            "2   [0.567788585513545, 0.5790120801906538, 0.7552...    [0.3709885337269968]\n",
            "3   [0.9904429183301491, 0.6050302164745696, 0.748...    [0.8288915058211973]\n",
            "4   [0.21861067016306124, 0.9048097235900721, 0.64...    [0.5349899690221575]\n",
            "5   [0.13563798176642794, 0.000800281208956588, 0....    [0.4435416540666909]\n",
            "6   [0.3737495928426252, 0.3520014035385838, 0.522...   [0.09305340317825461]\n",
            "7   [0.32302161376255345, 0.4994340049651702, 0.74...   [0.14783285319378414]\n",
            "8   [0.3434298380950769, 0.7032270239780244, 0.738...  [0.018189049444225502]\n",
            "9   [0.07089789369775956, 0.5638373406761586, 0.67...    [0.3547790938110622]\n",
            "10  [0.3408040592247046, 0.21694117904700638, 0.99...    [0.8239916875472871]\n",
            "11  [0.6598420501202575, 0.019962272021669114, 0.3...    [0.6523534918378481]\n",
            "12  [0.6232794458872679, 0.244403979290573, 0.7348...   [0.31841132093244096]\n",
            "13  [0.8478900232577973, 0.09503389627054948, 0.38...  [0.021372341057767974]\n",
            "14  [0.2626434231270294, 0.9290452161523913, 0.259...   [0.05928970476693818]\n",
            "\n",
            "Layer 4\n",
            "                                             weights                   bias\n",
            "0  [0.5384986130860498, 0.5584144891020211, 0.565...   [0.1676963666753597]\n",
            "1  [0.6989390607654253, 0.03272986420668633, 0.51...      [0.5208512408307]\n",
            "2  [0.37665576178143734, 0.28335434475578947, 0.9...   [0.8960993128182343]\n",
            "3  [0.2999929750770204, 0.9552450723777313, 0.868...    [0.850696553529853]\n",
            "4  [0.9796458345404008, 0.38456842430762406, 0.23...   [0.3956247234556418]\n",
            "5  [0.5917448427556706, 0.064890462760536, 0.8436...    [0.510776037260239]\n",
            "6  [0.6544391574114501, 0.6952336203502089, 0.087...   [0.7874221827376531]\n",
            "7  [0.5289611318482407, 0.6477550336803937, 0.747...  [0.33412623423201426]\n",
            "\n",
            "Layer 5\n",
            "                                             weights                  bias\n",
            "0  [0.3972385892083492, 0.42040514491932945, 0.11...  [0.4576654664358992]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  l1 = ntw[0]\n",
        "  for j in l1:\n",
        "    s = predict_y(j['weights'], j['bias'], X[i])\n",
        "    print(s)\n",
        ""
      ],
      "metadata": {
        "id": "HSuvui9-5tc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V6GP4mft7fzU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}